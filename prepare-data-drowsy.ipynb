{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport shutil\nimport random\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:33:59.850871Z","iopub.execute_input":"2023-03-24T12:33:59.851290Z","iopub.status.idle":"2023-03-24T12:33:59.856872Z","shell.execute_reply.started":"2023-03-24T12:33:59.851254Z","shell.execute_reply":"2023-03-24T12:33:59.855846Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"raw_data = r'/kaggle/input/mrl-eye-dataset'\nfor dirpath, dirname, filename in os.walk(raw_data):\n    for file in tqdm([f for f in filename if f.endswith('.png')]):\n        if file.split('_')[4] == '0':\n            path=r'/kaggle/working/train/closed eyes'\n            if not os.path.exists(path):\n                os.makedirs(path)\n            shutil.copy(src=dirpath + '/' + file, dst= path)\n        elif file.split('_')[4] == '1':\n            path=r'/kaggle/working/train/open eyes'\n            if not os.path.exists(path):\n                os.makedirs(path)\n            shutil.copy(src=dirpath + '/' + file, dst= path)        ","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:33:59.859164Z","iopub.execute_input":"2023-03-24T12:33:59.860083Z","iopub.status.idle":"2023-03-24T12:47:19.234047Z","shell.execute_reply.started":"2023-03-24T12:33:59.860037Z","shell.execute_reply":"2023-03-24T12:47:19.232738Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]\n0it [00:00, ?it/s]\n100%|██████████| 41946/41946 [05:26<00:00, 128.50it/s]\n100%|██████████| 42952/42952 [05:46<00:00, 124.10it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_test_closed(source, destination, percent):\n    '''\n    divides closed eyes images into given percent and moves from\n    source to destination.\n    \n    Arguments:\n    source(path): path of source directory\n    destination(path): path of destination directory\n    percent(float): percent of data to be divided(range: 0 to 1)\n    '''\n    path, dirs, files_closed = next(os.walk(source))\n    file_count_closed = len(files_closed)\n    percentage = file_count_closed * percent\n    to_move = random.sample(glob.glob(source + \"/*.png\"), int(percentage))\n\n    for f in enumerate(to_move):\n        if not os.path.exists(destination):\n            os.makedirs(destination)\n        shutil.move(f[1], destination)\n    print(f'moved {int(percentage)} images to the destination successfully.')    ","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:19.235890Z","iopub.execute_input":"2023-03-24T12:47:19.236236Z","iopub.status.idle":"2023-03-24T12:47:19.245662Z","shell.execute_reply.started":"2023-03-24T12:47:19.236204Z","shell.execute_reply":"2023-03-24T12:47:19.244332Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_test_open(source, destination, percent):\n    '''\n    divides open eyes images into given percent and moves from\n    source to destination.\n    \n    Arguments:\n    source(path): path of source directory\n    destination(path): path of destination directory\n    percent(float): percent of data to be divided(range: 0 to 1)\n    '''\n    path, dirs, files_open = next(os.walk(source))\n    file_count_open = len(files_open)\n    percentage = file_count_open * percent\n    to_move = random.sample(glob.glob(source + \"/*.png\"), int(percentage))\n\n    for f in enumerate(to_move):\n        if not os.path.exists(destination):\n            os.makedirs(destination)\n        shutil.move(f[1], destination)\n    print(f'moved {int(percentage)} images to the destination successfully.')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:19.247153Z","iopub.execute_input":"2023-03-24T12:47:19.247653Z","iopub.status.idle":"2023-03-24T12:47:19.259810Z","shell.execute_reply.started":"2023-03-24T12:47:19.247606Z","shell.execute_reply":"2023-03-24T12:47:19.258529Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"create_test_closed(r'/kaggle/working/train/closed eyes', \n                    r'/kaggle/working/test/closed eyes', \n                    0.2)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:19.263225Z","iopub.execute_input":"2023-03-24T12:47:19.263787Z","iopub.status.idle":"2023-03-24T12:47:19.931563Z","shell.execute_reply.started":"2023-03-24T12:47:19.263735Z","shell.execute_reply":"2023-03-24T12:47:19.930358Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"moved 8389 images to the destination successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"create_test_open(r'/kaggle/working/train/open eyes', \n                    r'/kaggle/working/test/open eyes', \n                    0.2)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:19.933997Z","iopub.execute_input":"2023-03-24T12:47:19.934776Z","iopub.status.idle":"2023-03-24T12:47:20.601685Z","shell.execute_reply.started":"2023-03-24T12:47:19.934735Z","shell.execute_reply":"2023-03-24T12:47:20.600704Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"moved 8590 images to the destination successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dropout,Input,Flatten,Dense,MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator  # Data Augumentation","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:20.603171Z","iopub.execute_input":"2023-03-24T12:47:20.603775Z","iopub.status.idle":"2023-03-24T12:47:29.723489Z","shell.execute_reply.started":"2023-03-24T12:47:20.603738Z","shell.execute_reply":"2023-03-24T12:47:29.722456Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:29.725232Z","iopub.execute_input":"2023-03-24T12:47:29.726535Z","iopub.status.idle":"2023-03-24T12:47:29.741584Z","shell.execute_reply.started":"2023-03-24T12:47:29.726480Z","shell.execute_reply":"2023-03-24T12:47:29.740444Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"batchsize=8","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:29.743136Z","iopub.execute_input":"2023-03-24T12:47:29.744162Z","iopub.status.idle":"2023-03-24T12:47:29.753007Z","shell.execute_reply.started":"2023-03-24T12:47:29.744104Z","shell.execute_reply":"2023-03-24T12:47:29.751682Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_datagen= ImageDataGenerator(rescale=1./255, rotation_range=0.2,shear_range=0.2,\n    zoom_range=0.2,width_shift_range=0.2,\n    height_shift_range=0.2, validation_split=0.2)\n\ntrain_data= train_datagen.flow_from_directory(r'/kaggle/working/train',\n                                target_size=(80,80),batch_size=batchsize,class_mode='categorical',subset='training' )\n\nvalidation_data= train_datagen.flow_from_directory(r'/kaggle/working/train',\n                                target_size=(80,80),batch_size=batchsize,class_mode='categorical', subset='validation')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:29.755054Z","iopub.execute_input":"2023-03-24T12:47:29.755891Z","iopub.status.idle":"2023-03-24T12:47:32.034781Z","shell.execute_reply.started":"2023-03-24T12:47:29.755835Z","shell.execute_reply":"2023-03-24T12:47:32.033826Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Found 54336 images belonging to 2 classes.\nFound 13583 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_data = test_datagen.flow_from_directory(r'/kaggle/working/test',\n                                target_size=(80,80),batch_size=batchsize,class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:32.039584Z","iopub.execute_input":"2023-03-24T12:47:32.039939Z","iopub.status.idle":"2023-03-24T12:47:32.488475Z","shell.execute_reply.started":"2023-03-24T12:47:32.039904Z","shell.execute_reply":"2023-03-24T12:47:32.487243Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Found 16979 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"bmodel = InceptionV3(include_top=False, weights='imagenet', input_tensor=Input(shape=(80,80,3)))\nhmodel = bmodel.output\nhmodel = Flatten()(hmodel)\nhmodel = Dense(64, activation='relu')(hmodel)\nhmodel = Dropout(0.5)(hmodel)\nhmodel = Dense(2,activation= 'softmax')(hmodel)\n\nmodel = Model(inputs=bmodel.input, outputs= hmodel)\nfor layer in bmodel.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:32.489833Z","iopub.execute_input":"2023-03-24T12:47:32.490192Z","iopub.status.idle":"2023-03-24T12:47:36.270293Z","shell.execute_reply.started":"2023-03-24T12:47:32.490157Z","shell.execute_reply":"2023-03-24T12:47:36.269073Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:36.271675Z","iopub.execute_input":"2023-03-24T12:47:36.273039Z","iopub.status.idle":"2023-03-24T12:47:37.107908Z","shell.execute_reply.started":"2023-03-24T12:47:36.272997Z","shell.execute_reply":"2023-03-24T12:47:37.107072Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 80, 80, 3)]  0           []                               \n                                                                                                  \n conv2d (Conv2D)                (None, 39, 39, 32)   864         ['input_1[0][0]']                \n                                                                                                  \n batch_normalization (BatchNorm  (None, 39, 39, 32)  96          ['conv2d[0][0]']                 \n alization)                                                                                       \n                                                                                                  \n activation (Activation)        (None, 39, 39, 32)   0           ['batch_normalization[0][0]']    \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 37, 37, 32)   9216        ['activation[0][0]']             \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 37, 37, 32)  96          ['conv2d_1[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_1 (Activation)      (None, 37, 37, 32)   0           ['batch_normalization_1[0][0]']  \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 37, 37, 64)   18432       ['activation_1[0][0]']           \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 37, 37, 64)  192         ['conv2d_2[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_2 (Activation)      (None, 37, 37, 64)   0           ['batch_normalization_2[0][0]']  \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 18, 18, 64)   0           ['activation_2[0][0]']           \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 18, 18, 80)   5120        ['max_pooling2d[0][0]']          \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 18, 18, 80)  240         ['conv2d_3[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_3 (Activation)      (None, 18, 18, 80)   0           ['batch_normalization_3[0][0]']  \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 16, 16, 192)  138240      ['activation_3[0][0]']           \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 16, 16, 192)  576        ['conv2d_4[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_4 (Activation)      (None, 16, 16, 192)  0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 192)   0           ['activation_4[0][0]']           \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 7, 7, 64)     12288       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 7, 7, 64)    192         ['conv2d_8[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_8 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 7, 7, 48)     9216        ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 7, 7, 96)     55296       ['activation_8[0][0]']           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 7, 7, 48)    144         ['conv2d_6[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 7, 7, 96)    288         ['conv2d_9[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n activation_6 (Activation)      (None, 7, 7, 48)     0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n activation_9 (Activation)      (None, 7, 7, 96)     0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n average_pooling2d (AveragePool  (None, 7, 7, 192)   0           ['max_pooling2d_1[0][0]']        \n ing2D)                                                                                           \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 7, 7, 64)     12288       ['max_pooling2d_1[0][0]']        \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 7, 7, 64)     76800       ['activation_6[0][0]']           \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_9[0][0]']           \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 7, 7, 32)     6144        ['average_pooling2d[0][0]']      \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 7, 7, 64)    192         ['conv2d_5[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 7, 7, 64)    192         ['conv2d_7[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 7, 7, 96)    288         ['conv2d_10[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 7, 7, 32)    96          ['conv2d_11[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_5 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n activation_7 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n activation_10 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_10[0][0]'] \n                                                                                                  \n activation_11 (Activation)     (None, 7, 7, 32)     0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n mixed0 (Concatenate)           (None, 7, 7, 256)    0           ['activation_5[0][0]',           \n                                                                  'activation_7[0][0]',           \n                                                                  'activation_10[0][0]',          \n                                                                  'activation_11[0][0]']          \n                                                                                                  \n conv2d_15 (Conv2D)             (None, 7, 7, 64)     16384       ['mixed0[0][0]']                 \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 7, 7, 64)    192         ['conv2d_15[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_15 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_15[0][0]'] \n                                                                                                  \n conv2d_13 (Conv2D)             (None, 7, 7, 48)     12288       ['mixed0[0][0]']                 \n                                                                                                  \n conv2d_16 (Conv2D)             (None, 7, 7, 96)     55296       ['activation_15[0][0]']          \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 7, 7, 48)    144         ['conv2d_13[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 7, 7, 96)    288         ['conv2d_16[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_13 (Activation)     (None, 7, 7, 48)     0           ['batch_normalization_13[0][0]'] \n                                                                                                  \n activation_16 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_16[0][0]'] \n                                                                                                  \n average_pooling2d_1 (AveragePo  (None, 7, 7, 256)   0           ['mixed0[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_12 (Conv2D)             (None, 7, 7, 64)     16384       ['mixed0[0][0]']                 \n                                                                                                  \n conv2d_14 (Conv2D)             (None, 7, 7, 64)     76800       ['activation_13[0][0]']          \n                                                                                                  \n conv2d_17 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_16[0][0]']          \n                                                                                                  \n conv2d_18 (Conv2D)             (None, 7, 7, 64)     16384       ['average_pooling2d_1[0][0]']    \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 7, 7, 64)    192         ['conv2d_12[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 7, 7, 64)    192         ['conv2d_14[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 7, 7, 96)    288         ['conv2d_17[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_18 (BatchN  (None, 7, 7, 64)    192         ['conv2d_18[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_12 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n activation_14 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_14[0][0]'] \n                                                                                                  \n activation_17 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_17[0][0]'] \n                                                                                                  \n activation_18 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_18[0][0]'] \n                                                                                                  \n mixed1 (Concatenate)           (None, 7, 7, 288)    0           ['activation_12[0][0]',          \n                                                                  'activation_14[0][0]',          \n                                                                  'activation_17[0][0]',          \n                                                                  'activation_18[0][0]']          \n                                                                                                  \n conv2d_22 (Conv2D)             (None, 7, 7, 64)     18432       ['mixed1[0][0]']                 \n                                                                                                  \n batch_normalization_22 (BatchN  (None, 7, 7, 64)    192         ['conv2d_22[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_22 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_22[0][0]'] \n                                                                                                  \n conv2d_20 (Conv2D)             (None, 7, 7, 48)     13824       ['mixed1[0][0]']                 \n                                                                                                  \n conv2d_23 (Conv2D)             (None, 7, 7, 96)     55296       ['activation_22[0][0]']          \n                                                                                                  \n batch_normalization_20 (BatchN  (None, 7, 7, 48)    144         ['conv2d_20[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_23 (BatchN  (None, 7, 7, 96)    288         ['conv2d_23[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_20 (Activation)     (None, 7, 7, 48)     0           ['batch_normalization_20[0][0]'] \n                                                                                                  \n activation_23 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_23[0][0]'] \n                                                                                                  \n average_pooling2d_2 (AveragePo  (None, 7, 7, 288)   0           ['mixed1[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_19 (Conv2D)             (None, 7, 7, 64)     18432       ['mixed1[0][0]']                 \n                                                                                                  \n conv2d_21 (Conv2D)             (None, 7, 7, 64)     76800       ['activation_20[0][0]']          \n                                                                                                  \n conv2d_24 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_23[0][0]']          \n                                                                                                  \n conv2d_25 (Conv2D)             (None, 7, 7, 64)     18432       ['average_pooling2d_2[0][0]']    \n                                                                                                  \n batch_normalization_19 (BatchN  (None, 7, 7, 64)    192         ['conv2d_19[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_21 (BatchN  (None, 7, 7, 64)    192         ['conv2d_21[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_24 (BatchN  (None, 7, 7, 96)    288         ['conv2d_24[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_25 (BatchN  (None, 7, 7, 64)    192         ['conv2d_25[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_19 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_19[0][0]'] \n                                                                                                  \n activation_21 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_21[0][0]'] \n                                                                                                  \n activation_24 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_24[0][0]'] \n                                                                                                  \n activation_25 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_25[0][0]'] \n                                                                                                  \n mixed2 (Concatenate)           (None, 7, 7, 288)    0           ['activation_19[0][0]',          \n                                                                  'activation_21[0][0]',          \n                                                                  'activation_24[0][0]',          \n                                                                  'activation_25[0][0]']          \n                                                                                                  \n conv2d_27 (Conv2D)             (None, 7, 7, 64)     18432       ['mixed2[0][0]']                 \n                                                                                                  \n batch_normalization_27 (BatchN  (None, 7, 7, 64)    192         ['conv2d_27[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_27 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_27[0][0]'] \n                                                                                                  \n conv2d_28 (Conv2D)             (None, 7, 7, 96)     55296       ['activation_27[0][0]']          \n                                                                                                  \n batch_normalization_28 (BatchN  (None, 7, 7, 96)    288         ['conv2d_28[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_28 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_28[0][0]'] \n                                                                                                  \n conv2d_26 (Conv2D)             (None, 3, 3, 384)    995328      ['mixed2[0][0]']                 \n                                                                                                  \n conv2d_29 (Conv2D)             (None, 3, 3, 96)     82944       ['activation_28[0][0]']          \n                                                                                                  \n batch_normalization_26 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_26[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_29 (BatchN  (None, 3, 3, 96)    288         ['conv2d_29[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_26 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_26[0][0]'] \n                                                                                                  \n activation_29 (Activation)     (None, 3, 3, 96)     0           ['batch_normalization_29[0][0]'] \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 288)   0           ['mixed2[0][0]']                 \n                                                                                                  \n mixed3 (Concatenate)           (None, 3, 3, 768)    0           ['activation_26[0][0]',          \n                                                                  'activation_29[0][0]',          \n                                                                  'max_pooling2d_2[0][0]']        \n                                                                                                  \n conv2d_34 (Conv2D)             (None, 3, 3, 128)    98304       ['mixed3[0][0]']                 \n                                                                                                  \n batch_normalization_34 (BatchN  (None, 3, 3, 128)   384         ['conv2d_34[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_34 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_34[0][0]'] \n                                                                                                  \n conv2d_35 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_34[0][0]']          \n                                                                                                  \n batch_normalization_35 (BatchN  (None, 3, 3, 128)   384         ['conv2d_35[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_35 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_35[0][0]'] \n                                                                                                  \n conv2d_31 (Conv2D)             (None, 3, 3, 128)    98304       ['mixed3[0][0]']                 \n                                                                                                  \n conv2d_36 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_35[0][0]']          \n                                                                                                  \n batch_normalization_31 (BatchN  (None, 3, 3, 128)   384         ['conv2d_31[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_36 (BatchN  (None, 3, 3, 128)   384         ['conv2d_36[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_31 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_31[0][0]'] \n                                                                                                  \n activation_36 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_36[0][0]'] \n                                                                                                  \n conv2d_32 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_31[0][0]']          \n                                                                                                  \n conv2d_37 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_36[0][0]']          \n                                                                                                  \n batch_normalization_32 (BatchN  (None, 3, 3, 128)   384         ['conv2d_32[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_37 (BatchN  (None, 3, 3, 128)   384         ['conv2d_37[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_32 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_32[0][0]'] \n                                                                                                  \n activation_37 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_37[0][0]'] \n                                                                                                  \n average_pooling2d_3 (AveragePo  (None, 3, 3, 768)   0           ['mixed3[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_30 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed3[0][0]']                 \n                                                                                                  \n conv2d_33 (Conv2D)             (None, 3, 3, 192)    172032      ['activation_32[0][0]']          \n                                                                                                  \n conv2d_38 (Conv2D)             (None, 3, 3, 192)    172032      ['activation_37[0][0]']          \n                                                                                                  \n conv2d_39 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_3[0][0]']    \n                                                                                                  \n batch_normalization_30 (BatchN  (None, 3, 3, 192)   576         ['conv2d_30[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_33 (BatchN  (None, 3, 3, 192)   576         ['conv2d_33[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_38 (BatchN  (None, 3, 3, 192)   576         ['conv2d_38[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_39 (BatchN  (None, 3, 3, 192)   576         ['conv2d_39[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_30 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_30[0][0]'] \n                                                                                                  \n activation_33 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_33[0][0]'] \n                                                                                                  \n activation_38 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_38[0][0]'] \n                                                                                                  \n activation_39 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_39[0][0]'] \n                                                                                                  \n mixed4 (Concatenate)           (None, 3, 3, 768)    0           ['activation_30[0][0]',          \n                                                                  'activation_33[0][0]',          \n                                                                  'activation_38[0][0]',          \n                                                                  'activation_39[0][0]']          \n                                                                                                  \n conv2d_44 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed4[0][0]']                 \n                                                                                                  \n batch_normalization_44 (BatchN  (None, 3, 3, 160)   480         ['conv2d_44[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_44 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_44[0][0]'] \n                                                                                                  \n conv2d_45 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_44[0][0]']          \n                                                                                                  \n batch_normalization_45 (BatchN  (None, 3, 3, 160)   480         ['conv2d_45[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_45 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_45[0][0]'] \n                                                                                                  \n conv2d_41 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed4[0][0]']                 \n                                                                                                  \n conv2d_46 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_45[0][0]']          \n                                                                                                  \n batch_normalization_41 (BatchN  (None, 3, 3, 160)   480         ['conv2d_41[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_46 (BatchN  (None, 3, 3, 160)   480         ['conv2d_46[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_41 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_41[0][0]'] \n                                                                                                  \n activation_46 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_46[0][0]'] \n                                                                                                  \n conv2d_42 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_41[0][0]']          \n                                                                                                  \n conv2d_47 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_46[0][0]']          \n                                                                                                  \n batch_normalization_42 (BatchN  (None, 3, 3, 160)   480         ['conv2d_42[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_47 (BatchN  (None, 3, 3, 160)   480         ['conv2d_47[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_42 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_42[0][0]'] \n                                                                                                  \n activation_47 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_47[0][0]'] \n                                                                                                  \n average_pooling2d_4 (AveragePo  (None, 3, 3, 768)   0           ['mixed4[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_40 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed4[0][0]']                 \n                                                                                                  \n conv2d_43 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_42[0][0]']          \n                                                                                                  \n conv2d_48 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_47[0][0]']          \n                                                                                                  \n conv2d_49 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_4[0][0]']    \n                                                                                                  \n batch_normalization_40 (BatchN  (None, 3, 3, 192)   576         ['conv2d_40[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_43 (BatchN  (None, 3, 3, 192)   576         ['conv2d_43[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_48 (BatchN  (None, 3, 3, 192)   576         ['conv2d_48[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_49 (BatchN  (None, 3, 3, 192)   576         ['conv2d_49[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_40 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_40[0][0]'] \n                                                                                                  \n activation_43 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_43[0][0]'] \n                                                                                                  \n activation_48 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_48[0][0]'] \n                                                                                                  \n activation_49 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_49[0][0]'] \n                                                                                                  \n mixed5 (Concatenate)           (None, 3, 3, 768)    0           ['activation_40[0][0]',          \n                                                                  'activation_43[0][0]',          \n                                                                  'activation_48[0][0]',          \n                                                                  'activation_49[0][0]']          \n                                                                                                  \n conv2d_54 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed5[0][0]']                 \n                                                                                                  \n batch_normalization_54 (BatchN  (None, 3, 3, 160)   480         ['conv2d_54[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_54 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_54[0][0]'] \n                                                                                                  \n conv2d_55 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_54[0][0]']          \n                                                                                                  \n batch_normalization_55 (BatchN  (None, 3, 3, 160)   480         ['conv2d_55[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_55 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_55[0][0]'] \n                                                                                                  \n conv2d_51 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed5[0][0]']                 \n                                                                                                  \n conv2d_56 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_55[0][0]']          \n                                                                                                  \n batch_normalization_51 (BatchN  (None, 3, 3, 160)   480         ['conv2d_51[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_56 (BatchN  (None, 3, 3, 160)   480         ['conv2d_56[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_51 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_51[0][0]'] \n                                                                                                  \n activation_56 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_56[0][0]'] \n                                                                                                  \n conv2d_52 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_51[0][0]']          \n                                                                                                  \n conv2d_57 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_56[0][0]']          \n                                                                                                  \n batch_normalization_52 (BatchN  (None, 3, 3, 160)   480         ['conv2d_52[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_57 (BatchN  (None, 3, 3, 160)   480         ['conv2d_57[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_52 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_52[0][0]'] \n                                                                                                  \n activation_57 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_57[0][0]'] \n                                                                                                  \n average_pooling2d_5 (AveragePo  (None, 3, 3, 768)   0           ['mixed5[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_50 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed5[0][0]']                 \n                                                                                                  \n conv2d_53 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_52[0][0]']          \n                                                                                                  \n conv2d_58 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_57[0][0]']          \n                                                                                                  \n conv2d_59 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_5[0][0]']    \n                                                                                                  \n batch_normalization_50 (BatchN  (None, 3, 3, 192)   576         ['conv2d_50[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_53 (BatchN  (None, 3, 3, 192)   576         ['conv2d_53[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_58 (BatchN  (None, 3, 3, 192)   576         ['conv2d_58[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_59 (BatchN  (None, 3, 3, 192)   576         ['conv2d_59[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_50 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_50[0][0]'] \n                                                                                                  \n activation_53 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_53[0][0]'] \n                                                                                                  \n activation_58 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_58[0][0]'] \n                                                                                                  \n activation_59 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_59[0][0]'] \n                                                                                                  \n mixed6 (Concatenate)           (None, 3, 3, 768)    0           ['activation_50[0][0]',          \n                                                                  'activation_53[0][0]',          \n                                                                  'activation_58[0][0]',          \n                                                                  'activation_59[0][0]']          \n                                                                                                  \n conv2d_64 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n batch_normalization_64 (BatchN  (None, 3, 3, 192)   576         ['conv2d_64[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_64 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_64[0][0]'] \n                                                                                                  \n conv2d_65 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_64[0][0]']          \n                                                                                                  \n batch_normalization_65 (BatchN  (None, 3, 3, 192)   576         ['conv2d_65[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_65 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_65[0][0]'] \n                                                                                                  \n conv2d_61 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n conv2d_66 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_65[0][0]']          \n                                                                                                  \n batch_normalization_61 (BatchN  (None, 3, 3, 192)   576         ['conv2d_61[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_66 (BatchN  (None, 3, 3, 192)   576         ['conv2d_66[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_61 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_61[0][0]'] \n                                                                                                  \n activation_66 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_66[0][0]'] \n                                                                                                  \n conv2d_62 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_61[0][0]']          \n                                                                                                  \n conv2d_67 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_66[0][0]']          \n                                                                                                  \n batch_normalization_62 (BatchN  (None, 3, 3, 192)   576         ['conv2d_62[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_67 (BatchN  (None, 3, 3, 192)   576         ['conv2d_67[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_62 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_62[0][0]'] \n                                                                                                  \n activation_67 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_67[0][0]'] \n                                                                                                  \n average_pooling2d_6 (AveragePo  (None, 3, 3, 768)   0           ['mixed6[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_60 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed6[0][0]']                 \n                                                                                                  \n conv2d_63 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_62[0][0]']          \n                                                                                                  \n conv2d_68 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_67[0][0]']          \n                                                                                                  \n conv2d_69 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_6[0][0]']    \n                                                                                                  \n batch_normalization_60 (BatchN  (None, 3, 3, 192)   576         ['conv2d_60[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_63 (BatchN  (None, 3, 3, 192)   576         ['conv2d_63[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_68 (BatchN  (None, 3, 3, 192)   576         ['conv2d_68[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_69 (BatchN  (None, 3, 3, 192)   576         ['conv2d_69[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_60 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_60[0][0]'] \n                                                                                                  \n activation_63 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_63[0][0]'] \n                                                                                                  \n activation_68 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_68[0][0]'] \n                                                                                                  \n activation_69 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_69[0][0]'] \n                                                                                                  \n mixed7 (Concatenate)           (None, 3, 3, 768)    0           ['activation_60[0][0]',          \n                                                                  'activation_63[0][0]',          \n                                                                  'activation_68[0][0]',          \n                                                                  'activation_69[0][0]']          \n                                                                                                  \n conv2d_72 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed7[0][0]']                 \n                                                                                                  \n batch_normalization_72 (BatchN  (None, 3, 3, 192)   576         ['conv2d_72[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_72 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_72[0][0]'] \n                                                                                                  \n conv2d_73 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_72[0][0]']          \n                                                                                                  \n batch_normalization_73 (BatchN  (None, 3, 3, 192)   576         ['conv2d_73[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_73 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_73[0][0]'] \n                                                                                                  \n conv2d_70 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed7[0][0]']                 \n                                                                                                  \n conv2d_74 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_73[0][0]']          \n                                                                                                  \n batch_normalization_70 (BatchN  (None, 3, 3, 192)   576         ['conv2d_70[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_74 (BatchN  (None, 3, 3, 192)   576         ['conv2d_74[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_70 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_70[0][0]'] \n                                                                                                  \n activation_74 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_74[0][0]'] \n                                                                                                  \n conv2d_71 (Conv2D)             (None, 1, 1, 320)    552960      ['activation_70[0][0]']          \n                                                                                                  \n conv2d_75 (Conv2D)             (None, 1, 1, 192)    331776      ['activation_74[0][0]']          \n                                                                                                  \n batch_normalization_71 (BatchN  (None, 1, 1, 320)   960         ['conv2d_71[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_75 (BatchN  (None, 1, 1, 192)   576         ['conv2d_75[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_71 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_71[0][0]'] \n                                                                                                  \n activation_75 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_75[0][0]'] \n                                                                                                  \n max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 768)   0           ['mixed7[0][0]']                 \n                                                                                                  \n mixed8 (Concatenate)           (None, 1, 1, 1280)   0           ['activation_71[0][0]',          \n                                                                  'activation_75[0][0]',          \n                                                                  'max_pooling2d_3[0][0]']        \n                                                                                                  \n conv2d_80 (Conv2D)             (None, 1, 1, 448)    573440      ['mixed8[0][0]']                 \n                                                                                                  \n batch_normalization_80 (BatchN  (None, 1, 1, 448)   1344        ['conv2d_80[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_80 (Activation)     (None, 1, 1, 448)    0           ['batch_normalization_80[0][0]'] \n                                                                                                  \n conv2d_77 (Conv2D)             (None, 1, 1, 384)    491520      ['mixed8[0][0]']                 \n                                                                                                  \n conv2d_81 (Conv2D)             (None, 1, 1, 384)    1548288     ['activation_80[0][0]']          \n                                                                                                  \n batch_normalization_77 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_77[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_81 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_81[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_77 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_77[0][0]'] \n                                                                                                  \n activation_81 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_81[0][0]'] \n                                                                                                  \n conv2d_78 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_77[0][0]']          \n                                                                                                  \n conv2d_79 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_77[0][0]']          \n                                                                                                  \n conv2d_82 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_81[0][0]']          \n                                                                                                  \n conv2d_83 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_81[0][0]']          \n                                                                                                  \n average_pooling2d_7 (AveragePo  (None, 1, 1, 1280)  0           ['mixed8[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_76 (Conv2D)             (None, 1, 1, 320)    409600      ['mixed8[0][0]']                 \n                                                                                                  \n batch_normalization_78 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_78[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_79 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_79[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_82 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_82[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_83 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_83[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n conv2d_84 (Conv2D)             (None, 1, 1, 192)    245760      ['average_pooling2d_7[0][0]']    \n                                                                                                  \n batch_normalization_76 (BatchN  (None, 1, 1, 320)   960         ['conv2d_76[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_78 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_78[0][0]'] \n                                                                                                  \n activation_79 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_79[0][0]'] \n                                                                                                  \n activation_82 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_82[0][0]'] \n                                                                                                  \n activation_83 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_83[0][0]'] \n                                                                                                  \n batch_normalization_84 (BatchN  (None, 1, 1, 192)   576         ['conv2d_84[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_76 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_76[0][0]'] \n                                                                                                  \n mixed9_0 (Concatenate)         (None, 1, 1, 768)    0           ['activation_78[0][0]',          \n                                                                  'activation_79[0][0]']          \n                                                                                                  \n concatenate (Concatenate)      (None, 1, 1, 768)    0           ['activation_82[0][0]',          \n                                                                  'activation_83[0][0]']          \n                                                                                                  \n activation_84 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_84[0][0]'] \n                                                                                                  \n mixed9 (Concatenate)           (None, 1, 1, 2048)   0           ['activation_76[0][0]',          \n                                                                  'mixed9_0[0][0]',               \n                                                                  'concatenate[0][0]',            \n                                                                  'activation_84[0][0]']          \n                                                                                                  \n conv2d_89 (Conv2D)             (None, 1, 1, 448)    917504      ['mixed9[0][0]']                 \n                                                                                                  \n batch_normalization_89 (BatchN  (None, 1, 1, 448)   1344        ['conv2d_89[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_89 (Activation)     (None, 1, 1, 448)    0           ['batch_normalization_89[0][0]'] \n                                                                                                  \n conv2d_86 (Conv2D)             (None, 1, 1, 384)    786432      ['mixed9[0][0]']                 \n                                                                                                  \n conv2d_90 (Conv2D)             (None, 1, 1, 384)    1548288     ['activation_89[0][0]']          \n                                                                                                  \n batch_normalization_86 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_86[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_90 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_90[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_86 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_86[0][0]'] \n                                                                                                  \n activation_90 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_90[0][0]'] \n                                                                                                  \n conv2d_87 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_86[0][0]']          \n                                                                                                  \n conv2d_88 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_86[0][0]']          \n                                                                                                  \n conv2d_91 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_90[0][0]']          \n                                                                                                  \n conv2d_92 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_90[0][0]']          \n                                                                                                  \n average_pooling2d_8 (AveragePo  (None, 1, 1, 2048)  0           ['mixed9[0][0]']                 \n oling2D)                                                                                         \n                                                                                                  \n conv2d_85 (Conv2D)             (None, 1, 1, 320)    655360      ['mixed9[0][0]']                 \n                                                                                                  \n batch_normalization_87 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_87[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_88 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_88[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_91 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_91[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_92 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_92[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n conv2d_93 (Conv2D)             (None, 1, 1, 192)    393216      ['average_pooling2d_8[0][0]']    \n                                                                                                  \n batch_normalization_85 (BatchN  (None, 1, 1, 320)   960         ['conv2d_85[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_87 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_87[0][0]'] \n                                                                                                  \n activation_88 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_88[0][0]'] \n                                                                                                  \n activation_91 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_91[0][0]'] \n                                                                                                  \n activation_92 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_92[0][0]'] \n                                                                                                  \n batch_normalization_93 (BatchN  (None, 1, 1, 192)   576         ['conv2d_93[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n activation_85 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_85[0][0]'] \n                                                                                                  \n mixed9_1 (Concatenate)         (None, 1, 1, 768)    0           ['activation_87[0][0]',          \n                                                                  'activation_88[0][0]']          \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 1, 1, 768)    0           ['activation_91[0][0]',          \n                                                                  'activation_92[0][0]']          \n                                                                                                  \n activation_93 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_93[0][0]'] \n                                                                                                  \n mixed10 (Concatenate)          (None, 1, 1, 2048)   0           ['activation_85[0][0]',          \n                                                                  'mixed9_1[0][0]',               \n                                                                  'concatenate_1[0][0]',          \n                                                                  'activation_93[0][0]']          \n                                                                                                  \n flatten (Flatten)              (None, 2048)         0           ['mixed10[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 64)           131136      ['flatten[0][0]']                \n                                                                                                  \n dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n                                                                                                  \n dense_1 (Dense)                (None, 2)            130         ['dropout[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 21,934,050\nTrainable params: 131,266\nNon-trainable params: 21,802,784\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:37.108912Z","iopub.execute_input":"2023-03-24T12:47:37.109295Z","iopub.status.idle":"2023-03-24T12:47:37.115263Z","shell.execute_reply.started":"2023-03-24T12:47:37.109260Z","shell.execute_reply":"2023-03-24T12:47:37.114113Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\n\nearlystop = EarlyStopping(monitor = 'val_loss', patience=7, verbose= 3, restore_best_weights=True)\n\nlearning_rate = ReduceLROnPlateau(monitor= 'val_loss', patience=3, verbose= 3, )\n\ncallbacks=[earlystop,learning_rate]","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:37.116501Z","iopub.execute_input":"2023-03-24T12:47:37.116829Z","iopub.status.idle":"2023-03-24T12:47:37.125121Z","shell.execute_reply.started":"2023-03-24T12:47:37.116780Z","shell.execute_reply":"2023-03-24T12:47:37.123808Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.fit_generator(train_data,steps_per_epoch=train_data.samples//batchsize,\n                   validation_data=validation_data,\n                   validation_steps=validation_data.samples//batchsize,\n                   callbacks=callbacks,\n                    epochs=20)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T12:47:37.126774Z","iopub.execute_input":"2023-03-24T12:47:37.127332Z","iopub.status.idle":"2023-03-24T15:56:15.741671Z","shell.execute_reply.started":"2023-03-24T12:47:37.127299Z","shell.execute_reply":"2023-03-24T15:56:15.740707Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  import sys\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n6792/6792 [==============================] - 511s 75ms/step - loss: 0.2053 - accuracy: 0.9201 - val_loss: 0.2437 - val_accuracy: 0.9033 - lr: 0.0010\nEpoch 2/20\n6792/6792 [==============================] - 571s 84ms/step - loss: 0.1810 - accuracy: 0.9309 - val_loss: 0.2517 - val_accuracy: 0.9076 - lr: 0.0010\nEpoch 3/20\n6792/6792 [==============================] - 510s 75ms/step - loss: 0.1680 - accuracy: 0.9354 - val_loss: 0.2517 - val_accuracy: 0.9045 - lr: 0.0010\nEpoch 4/20\n6792/6792 [==============================] - 519s 76ms/step - loss: 0.1656 - accuracy: 0.9348 - val_loss: 0.2412 - val_accuracy: 0.8999 - lr: 0.0010\nEpoch 5/20\n6792/6792 [==============================] - 556s 82ms/step - loss: 0.1606 - accuracy: 0.9374 - val_loss: 0.2631 - val_accuracy: 0.8995 - lr: 0.0010\nEpoch 6/20\n6792/6792 [==============================] - 524s 77ms/step - loss: 0.1592 - accuracy: 0.9387 - val_loss: 0.2572 - val_accuracy: 0.8974 - lr: 0.0010\nEpoch 7/20\n6792/6792 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9408\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n6792/6792 [==============================] - 552s 81ms/step - loss: 0.1584 - accuracy: 0.9408 - val_loss: 0.2636 - val_accuracy: 0.9107 - lr: 0.0010\nEpoch 8/20\n6792/6792 [==============================] - 546s 80ms/step - loss: 0.1459 - accuracy: 0.9437 - val_loss: 0.2482 - val_accuracy: 0.9073 - lr: 1.0000e-04\nEpoch 9/20\n6792/6792 [==============================] - 504s 74ms/step - loss: 0.1424 - accuracy: 0.9451 - val_loss: 0.2428 - val_accuracy: 0.9120 - lr: 1.0000e-04\nEpoch 10/20\n6792/6792 [==============================] - 559s 82ms/step - loss: 0.1397 - accuracy: 0.9462 - val_loss: 0.2387 - val_accuracy: 0.9078 - lr: 1.0000e-04\nEpoch 11/20\n6792/6792 [==============================] - 516s 76ms/step - loss: 0.1398 - accuracy: 0.9477 - val_loss: 0.2319 - val_accuracy: 0.9109 - lr: 1.0000e-04\nEpoch 12/20\n6792/6792 [==============================] - 551s 81ms/step - loss: 0.1429 - accuracy: 0.9465 - val_loss: 0.2505 - val_accuracy: 0.9119 - lr: 1.0000e-04\nEpoch 13/20\n6792/6792 [==============================] - 568s 84ms/step - loss: 0.1400 - accuracy: 0.9473 - val_loss: 0.2299 - val_accuracy: 0.9134 - lr: 1.0000e-04\nEpoch 14/20\n6792/6792 [==============================] - 562s 83ms/step - loss: 0.1390 - accuracy: 0.9469 - val_loss: 0.2418 - val_accuracy: 0.9104 - lr: 1.0000e-04\nEpoch 15/20\n6792/6792 [==============================] - 559s 82ms/step - loss: 0.1345 - accuracy: 0.9491 - val_loss: 0.2427 - val_accuracy: 0.9120 - lr: 1.0000e-04\nEpoch 16/20\n6792/6792 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9484\nEpoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n6792/6792 [==============================] - 553s 81ms/step - loss: 0.1350 - accuracy: 0.9484 - val_loss: 0.2522 - val_accuracy: 0.9079 - lr: 1.0000e-04\nEpoch 17/20\n6792/6792 [==============================] - 560s 83ms/step - loss: 0.1335 - accuracy: 0.9494 - val_loss: 0.2493 - val_accuracy: 0.9109 - lr: 1.0000e-05\nEpoch 18/20\n6792/6792 [==============================] - 554s 82ms/step - loss: 0.1318 - accuracy: 0.9495 - val_loss: 0.2462 - val_accuracy: 0.9112 - lr: 1.0000e-05\nEpoch 19/20\n6792/6792 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.9483\nEpoch 19: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n6792/6792 [==============================] - 511s 75ms/step - loss: 0.1374 - accuracy: 0.9483 - val_loss: 0.2448 - val_accuracy: 0.9099 - lr: 1.0000e-05\nEpoch 20/20\n6792/6792 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9501Restoring model weights from the end of the best epoch: 13.\n6792/6792 [==============================] - 558s 82ms/step - loss: 0.1330 - accuracy: 0.9501 - val_loss: 0.2371 - val_accuracy: 0.9103 - lr: 1.0000e-06\nEpoch 20: early stopping\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f15b48dfa90>"},"metadata":{}}]},{"cell_type":"code","source":"acc_tr, loss_tr = model.evaluate_generator(train_data)\nprint(acc_tr)\nprint(loss_tr)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T15:56:15.743354Z","iopub.execute_input":"2023-03-24T15:56:15.743848Z","iopub.status.idle":"2023-03-24T16:02:37.750876Z","shell.execute_reply.started":"2023-03-24T15:56:15.743797Z","shell.execute_reply":"2023-03-24T16:02:37.749615Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"},{"name":"stdout","text":"0.12286439538002014\n0.9530329704284668\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom keras.models import load_model\n\n# Load the model\nmodel = load_model('/kaggle/working/model.h5')\n\n# Make predictions on the validation data\ny_pred = model.predict(validation_data)\n\n# Get the predicted class for each sample\ny_pred_classes = np.argmax(y_pred, axis=1)\n\n# Get the true class for each sample\ny_true = validation_data.classes\n\n# Calculate accuracy and validation accuracy\naccuracy = accuracy_score(y_true, y_pred_classes)\nvalidation_accuracy = model.evaluate(validation_data)[1]\n\n# Print the results\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Validation accuracy: {validation_accuracy}\")\n\n# Draw the confusion matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes)\nplt.imshow(confusion_mtx, interpolation='nearest', cmap=plt.cm.Blues)\nplt.colorbar()\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-24T16:24:43.730870Z","iopub.execute_input":"2023-03-24T16:24:43.732379Z","iopub.status.idle":"2023-03-24T16:28:26.417829Z","shell.execute_reply.started":"2023-03-24T16:24:43.732309Z","shell.execute_reply":"2023-03-24T16:28:26.416216Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"1698/1698 [==============================] - 112s 65ms/step\n1698/1698 [==============================] - 106s 62ms/step - loss: 0.2302 - accuracy: 0.9144\nAccuracy: 0.5026871825075462\nValidation accuracy: 0.91437828540802\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3862282619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtick_marks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick_marks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick_marks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'classes' is not defined"],"ename":"NameError","evalue":"name 'classes' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"model.save('/kaggle/working/model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T16:05:21.346761Z","iopub.execute_input":"2023-03-24T16:05:21.347329Z","iopub.status.idle":"2023-03-24T16:05:22.252963Z","shell.execute_reply.started":"2023-03-24T16:05:21.347282Z","shell.execute_reply":"2023-03-24T16:05:22.251100Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nhistory= model.evaluate_generator(train_data)\n\n# Plot accuracy and loss curves\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-24T17:02:55.616423Z","iopub.execute_input":"2023-03-24T17:02:55.616892Z","iopub.status.idle":"2023-03-24T17:10:17.643647Z","shell.execute_reply.started":"2023-03-24T17:02:55.616850Z","shell.execute_reply":"2023-03-24T17:10:17.642549Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n  This is separate from the ipykernel package so we can avoid doing imports until\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/495604472.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Plot accuracy and loss curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'history'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'history'","output_type":"error"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Load the saved model\nmodel = tf.keras.models.load_model('/path/to/model.h5')\n\n# Evaluate the model on the test data\ntest_loss, test_acc = model.evaluate(test_data)\n\n# Plot the accuracy curve\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\n# Plot the loss curve\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Make predictions on the validation data\ny_pred = model.predict(validation_data)\n\n# Get the predicted class for each sample\ny_pred_classes = np.argmax(y_pred, axis=1)\n\n# Get the true class for each sample\ny_true = validation_data.classes\n\n# Calculate confusion matrix\nconf_matrix = confusion_matrix(y_true, y_pred_classes)\n\n# Plot the confusion matrix\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-24T17:11:25.701665Z","iopub.execute_input":"2023-03-24T17:11:25.702110Z","iopub.status.idle":"2023-03-24T17:13:08.765730Z","shell.execute_reply.started":"2023-03-24T17:11:25.702071Z","shell.execute_reply":"2023-03-24T17:13:08.764755Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"1698/1698 [==============================] - 101s 60ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}]}]}